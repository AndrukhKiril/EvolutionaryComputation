{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from hamiltonian_cycle.algorithms.lab1 import init_random_solution\n",
    "from hamiltonian_cycle.algorithms.lab7 import LargeNeighborhoodSearch\n",
    "from hamiltonian_cycle.algorithms.lab2 import init_greedy_2regret_weighted_cycle\n",
    "from hamiltonian_cycle.algorithms.lab3_4 import LocalSearch\n",
    "from hamiltonian_cycle.costs import dm, function_cost\n",
    "from hamiltonian_cycle.plots import plot_solution\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(csv_path, sep=\";\", names=[\"x\", \"y\", \"cost\"])\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "\n",
    "ds_a = read_dataset_csv(DATA_DIR / \"TSPA.csv\")\n",
    "ds_b = read_dataset_csv(DATA_DIR / \"TSPB.csv\")\n",
    "\n",
    "dm_a = dm(ds_a)\n",
    "dm_b = dm(ds_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_edges(parent1: list[int], parent2: list[int]):\n",
    "    size = len(parent1)\n",
    "\n",
    "    # Convert edges to unordered pairs\n",
    "    parent1_edges = [\n",
    "        tuple(sorted((parent1[i], parent1[(i + 1) % size]))) for i in range(size)\n",
    "    ]\n",
    "    parent2_edges = [\n",
    "        tuple(sorted((parent2[i], parent2[(i + 1) % size]))) for i in range(size)\n",
    "    ]\n",
    "    common_edges = set(parent1_edges).intersection(parent2_edges)\n",
    "\n",
    "    return common_edges\n",
    "\n",
    "\n",
    "def combine_common_edges(\n",
    "    parent1: list[int], parent2: list[int], common_edges: set\n",
    ") -> list[int]:\n",
    "    # Randomly select either parent1 or parent2 as the starting point\n",
    "    starting_parent = random.choice([parent1, parent2])\n",
    "\n",
    "    # Start forming the child solution\n",
    "    child = []\n",
    "    # Add nodes from common edges in the order they appear in `starting_parent`\n",
    "    for node in starting_parent:\n",
    "        if any(node in edge for edge in common_edges):\n",
    "            child.append(node)\n",
    "    return child\n",
    "\n",
    "\n",
    "def recombination_operator_1(\n",
    "    parent1: list[int], parent2: list[int], all_nodes: list[int]\n",
    ") -> list[int]:\n",
    "    common_edges = find_common_edges(parent1, parent2)\n",
    "\n",
    "    child = combine_common_edges(parent1, parent2, common_edges)\n",
    "\n",
    "    # Fill remaining nodes randomly\n",
    "    remaining_nodes = [node for node in all_nodes if node not in child]\n",
    "    random.shuffle(remaining_nodes)\n",
    "\n",
    "    # Complete the solution to the required size\n",
    "    child.extend(remaining_nodes[: len(parent1) - len(child)])\n",
    "    return child\n",
    "\n",
    "\n",
    "def recombination_operator_2(\n",
    "    parent1: list[int], parent2: list[int], ds: pd.DataFrame, dm: pd.DataFrame\n",
    ") -> list[int]:\n",
    "    common_edges = find_common_edges(parent1, parent2)\n",
    "    child = combine_common_edges(parent1, parent2, common_edges)\n",
    "    child = init_greedy_2regret_weighted_cycle(\n",
    "        ds,\n",
    "        dm,\n",
    "        start=0,\n",
    "        w_cost=0.5,\n",
    "        w_regret=0.5,\n",
    "        initial_solution=child,\n",
    "    )\n",
    "    return child.index.tolist()\n",
    "\n",
    "\n",
    "def hea(\n",
    "    ds: pd.DataFrame,\n",
    "    dm: pd.DataFrame,\n",
    "    population_size: int = 20,\n",
    "    time_budget: float = 555,\n",
    "    use_operator_1_prob: float = 0.5,\n",
    "    with_local_search_after_recombination: bool = True,\n",
    "):\n",
    "    ls = LocalSearch(strategy=\"steepest\", intra_search=\"edge\")\n",
    "\n",
    "    def create_initial_solution(ds, dm):\n",
    "        return ls(ds, dm, init_random_solution(ds, dm, 0).index.tolist()).index.tolist()\n",
    "\n",
    "    population = [create_initial_solution(ds, dm) for _ in range(population_size)]\n",
    "\n",
    "    num_iterations = 0\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < time_budget:\n",
    "        num_iterations += 1\n",
    "\n",
    "        parent_ids = np.random.choice(range(population_size), 2, replace=False)\n",
    "        parent1, parent2 = population[parent_ids[0]], population[parent_ids[1]]\n",
    "\n",
    "        if random.random() < use_operator_1_prob:\n",
    "            child_solution = recombination_operator_1(parent1, parent2, list(ds.index))\n",
    "        else:\n",
    "            child_solution = recombination_operator_2(parent1, parent2, ds, dm)\n",
    "\n",
    "        if with_local_search_after_recombination:\n",
    "            child_solution = ls(ds, dm, child_solution).index.tolist()\n",
    "\n",
    "        child_cost = function_cost(ds.loc[child_solution])\n",
    "        population_costs = [function_cost(ds.loc[s]) for s in population]\n",
    "        # if child cost is smaller than the worst solution in the population, replace worst with the child\n",
    "        # here also it ensures that population is unique\n",
    "        if child_cost < max(population_costs) and child_cost not in population_costs:\n",
    "            population.pop(np.argmax(population_costs))\n",
    "            population.append(child_solution)\n",
    "\n",
    "    return population[\n",
    "        np.argmin(function_cost(ds.loc[s]) for s in population)\n",
    "    ], num_iterations\n",
    "\n",
    "\n",
    "class HEAMetrics:\n",
    "    def __init__(self, solution: list[int], num_iterations: float):\n",
    "        self.cost = function_cost(solution)\n",
    "        self.solution = list(solution.index)\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "\n",
    "def run_hea_a() -> HEAMetrics:\n",
    "    best_solution, num_iterations = hea(ds_a, dm_a)\n",
    "    return HEAMetrics(ds_a.loc[best_solution], num_iterations)\n",
    "\n",
    "\n",
    "def run_hea_b() -> HEAMetrics:\n",
    "    best_solution, num_iterations = hea(ds_b, dm_b)\n",
    "    return HEAMetrics(ds_b.loc[best_solution], num_iterations)\n",
    "\n",
    "\n",
    "HEA_RUNS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on DataSet A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_a: list[HEAMetrics] = Parallel(n_jobs=-1)(\n",
    "    delayed(run_hea_a)() for _ in range(HEA_RUNS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_a = min(metrics_a, key=lambda x: x.cost)\n",
    "mean_a = sum([metric.cost for metric in metrics_a]) / len(metrics_a)\n",
    "maximum_a = max(metrics_a, key=lambda x: x.cost)\n",
    "mean_n_iterations_a = sum([metric.num_iterations for metric in metrics_a]) / len(metrics_a)\n",
    "\n",
    "print(f\"Best solution: {minimum_a.solution}\")\n",
    "print(\"Objective function statistics:\")\n",
    "print(f\"{minimum_a.cost = }\\n{mean_a = }\\n{maximum_a.cost= }\")\n",
    "print(f\"Mean Number of iterations: {mean_n_iterations_a}\")\n",
    "plot_solution(ds_a, minimum_a.solution, title=\"HEA on dataset A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b: list[HEAMetrics] = Parallel(n_jobs=-1)(\n",
    "    delayed(run_hea_b)() for _ in range(HEA_RUNS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_b = min(metrics_b, key=lambda x: x.cost)\n",
    "mean_b = sum([metric.cost for metric in metrics_b]) / len(metrics_b)\n",
    "maximum_b = max(metrics_b, key=lambda x: x.cost)\n",
    "mean_n_iterations_b = sum([metric.num_iterations for metric in metrics_b]) / len(metrics_b)\n",
    "\n",
    "print(f\"Best solution: {minimum_b.solution}\")\n",
    "print(\"Objective function statistics:\")\n",
    "print(f\"{minimum_b.cost = }\\n{mean_b = }\\n{maximum_b.cost= }\")\n",
    "print(f\"Mean Number of iterations: {mean_n_iterations_b}\")\n",
    "plot_solution(ds_b, minimum_b.solution, title=\"HEA on dataset B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
