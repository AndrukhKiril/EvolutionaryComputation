{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uladzislau Lukashevich 155671, Kiril Andrukh 162069\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of a problem\n",
    "\n",
    "We are given three columns of integers with a row for each node. The first two columns contain x and y coordinates of the node positions in a plane. The third column contains node costs. The goal is to select exactly 50% of the nodes (if the number of nodes is odd we round the number of nodes to be selected up) and form a Hamiltonian cycle (closed path) through this set of nodes such that the sum of the total length of the path plus the total cost of the selected nodes is minimized.\n",
    "\n",
    "The distances between nodes are calculated as Euclidean distances rounded mathematically to\n",
    "integer values. The distance matrix should be calculated just after reading an instance and then only\n",
    "the distance matrix (no nodes coordinates) should be accessed by optimization methods to allow\n",
    "instances defined only by distance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from hamiltonian_cycle.algorithms.lab7 import LargeNeighborhoodSearch\n",
    "from hamiltonian_cycle.costs import dm, function_cost\n",
    "from hamiltonian_cycle.plots import plot_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(csv_path, sep=\";\", names=[\"x\", \"y\", \"cost\"])\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "\n",
    "ds_a = read_dataset_csv(DATA_DIR / \"TSPA.csv\")\n",
    "ds_b = read_dataset_csv(DATA_DIR / \"TSPB.csv\")\n",
    "\n",
    "dm_a = dm(ds_a)\n",
    "dm_b = dm(ds_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm: LargeNeighborhoodSearch**\n",
    "\n",
    "1.  start_time ← current_time()\n",
    "2.  num_iterations ← 0\n",
    "3.  best_s ← LocalSearch(InitRandomSolution(ds, dm))\n",
    "4.  best_cost ← Cost(best_s)\n",
    "5.  while current_time() - start_time < max_runtime:\n",
    "    1. num_iterations ← num_iterations + 1\n",
    "    2. s' ← Repair(ds, dm, w_cost, w_regret, Destroy(best_s))\n",
    "    3. if apply_local_search: s' ← LocalSearch(s')\n",
    "    4. if Cost(s') < best_cost: best_s, best_cost ← s', Cost(s')\n",
    "6. return best_s, num_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Destroy Operation**\n",
    "\n",
    "1. (segment_length, k_segments) ← `GenerateRandomSegmentsParams(length(solution), min_percentage=0.2, max_percentage=0.3)`\n",
    "2. longest_segments ← `FindKLongestSegments(dm, solution, segment_length, k_segments)`\n",
    "3. destroyed_solution ← `EliminateSegments(solution, longest_segments)`\n",
    "4. return destroyed_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSMetrics:\n",
    "    def __init__(self, solution: pd.DataFrame, num_iterations: float):\n",
    "        self.cost = function_cost(solution)\n",
    "        self.solution = list(solution.index)\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "\n",
    "def run_lns(lns: LargeNeighborhoodSearch) -> LNSMetrics:\n",
    "    lns_solution, num_iterations = lns()\n",
    "    return LNSMetrics(lns_solution, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_runtime_sec = 2200\n",
    "lns_a = LargeNeighborhoodSearch(\n",
    "    ds=ds_a,\n",
    "    dm=dm_a,\n",
    "    max_runtime=max_runtime_sec,\n",
    "    w_cost=0.5,\n",
    "    w_regret=0.5,\n",
    "    apply_local_search=True,\n",
    ")\n",
    "lns_runs = 20\n",
    "\n",
    "metrics: list[LNSMetrics] = Parallel(n_jobs=-1)(\n",
    "    delayed(run_lns)(lns_a) for _ in range(lns_runs)\n",
    ")\n",
    "\n",
    "minimum = min(metrics, key=lambda x: x.cost)\n",
    "mean = sum([metric.cost for metric in metrics]) / len(metrics)\n",
    "maximum = max(metrics, key=lambda x: x.cost)\n",
    "mean_n_iterations = sum([metric.num_iterations for metric in metrics]) / len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best solution: {minimum.solution}\")\n",
    "print(\"Objective function statistics:\")\n",
    "print(f\"{minimum.cost = }\\n{mean = }\\n{maximum.cost= }\")\n",
    "print(f\"Number of loop iterations: {mean_n_iterations}\")\n",
    "plot_solution(ds_a, minimum.solution, title=\"ILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_runtime_sec = 2200\n",
    "lns_b = LargeNeighborhoodSearch(\n",
    "    ds=ds_b,\n",
    "    dm=dm_b,\n",
    "    max_runtime=max_runtime_sec,\n",
    "    w_cost=0.5,\n",
    "    w_regret=0.5,\n",
    "    apply_local_search=True,\n",
    ")\n",
    "lns_runs = 20\n",
    "\n",
    "metrics: list[LNSMetrics] = Parallel(n_jobs=-1)(\n",
    "    delayed(run_lns)(lns_b) for _ in range(lns_runs)\n",
    ")\n",
    "\n",
    "minimum = min(metrics, key=lambda x: x.cost)\n",
    "mean = sum([metric.cost for metric in metrics]) / len(metrics)\n",
    "maximum = max(metrics, key=lambda x: x.cost)\n",
    "mean_n_iterations = sum([metric.num_iterations for metric in metrics]) / len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best solution: {minimum.solution}\")\n",
    "print(\"Objective function statistics:\")\n",
    "print(f\"{minimum.cost = }\\n{mean = }\\n{maximum.cost= }\")\n",
    "print(f\"Number of loop iterations: {mean_n_iterations}\")\n",
    "plot_solution(ds_b, minimum.solution, title=\"ILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results without LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_runtime_sec = 2200\n",
    "lns_a = LargeNeighborhoodSearch(\n",
    "    ds=ds_a,\n",
    "    dm=dm_a,\n",
    "    max_runtime=max_runtime_sec,\n",
    "    w_cost=0.5,\n",
    "    w_regret=0.5,\n",
    "    apply_local_search=False,\n",
    ")\n",
    "lns_runs = 20\n",
    "\n",
    "metrics: list[LNSMetrics] = Parallel(n_jobs=-1)(\n",
    "    delayed(run_lns)(lns_a) for _ in range(lns_runs)\n",
    ")\n",
    "\n",
    "minimum = min(metrics, key=lambda x: x.cost)\n",
    "mean = sum([metric.cost for metric in metrics]) / len(metrics)\n",
    "maximum = max(metrics, key=lambda x: x.cost)\n",
    "mean_n_iterations = sum([metric.num_iterations for metric in metrics]) / len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best solution: {minimum.solution}\")\n",
    "print(\"Objective function statistics:\")\n",
    "print(f\"{minimum.cost = }\\n{mean = }\\n{maximum.cost= }\")\n",
    "print(f\"Number of loop iterations: {mean_n_iterations}\")\n",
    "plot_solution(ds_a, minimum.solution, title=\"ILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_runtime_sec = 2200\n",
    "lns_b = LargeNeighborhoodSearch(\n",
    "    ds=ds_b,\n",
    "    dm=dm_b,\n",
    "    max_runtime=max_runtime_sec,\n",
    "    w_cost=0.5,\n",
    "    w_regret=0.5,\n",
    "    apply_local_search=False,\n",
    ")\n",
    "lns_runs = 20\n",
    "\n",
    "metrics: list[LNSMetrics] = Parallel(n_jobs=-1)(\n",
    "    delayed(run_lns)(lns_b) for _ in range(lns_runs)\n",
    ")\n",
    "\n",
    "minimum = min(metrics, key=lambda x: x.cost)\n",
    "mean = sum([metric.cost for metric in metrics]) / len(metrics)\n",
    "maximum = max(metrics, key=lambda x: x.cost)\n",
    "mean_n_iterations = sum([metric.num_iterations for metric in metrics]) / len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best solution: {minimum.solution}\")\n",
    "print(\"Objective function statistics:\")\n",
    "print(f\"{minimum.cost = }\\n{mean = }\\n{maximum.cost= }\")\n",
    "print(f\"Number of loop iterationss: {mean_n_iterations}\")\n",
    "plot_solution(ds_b, minimum.solution, title=\"ILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_res = pd.DataFrame(\n",
    "    {\n",
    "        \"Steepest edge LS\": [72046, 74033.715, 78801, 9.54, 1],\n",
    "        \"MLSM\": [70662, 71267.4, 71693, 2223, 200],\n",
    "        \"ILS\": [69107, 69326.15, 69765, 2223, 1106.2],\n",
    "        \"LNS with LS\": [69474, 70179.05, 71022, 2223, 3027.2],\n",
    "        \"LNS without LS\": [69657, 70494.5, 71452, 2223, 6705.1],\n",
    "        \"Greedy weighted cycle\": [71057.0, 72218.320, 73587.0, 0.4, 1],\n",
    "    },\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"Dataset A\", \"min\"),\n",
    "            (\"Dataset A\", \"mean\"),\n",
    "            (\"Dataset A\", \"max\"),\n",
    "            (\"Dataset A\", \"seconds/instance\"),\n",
    "            (\"Dataset A\", \"iterations\"),\n",
    "        ]\n",
    "    ),\n",
    ").T\n",
    "\n",
    "b_res = pd.DataFrame(\n",
    "    {\n",
    "        \"Steepest edge LS\": [45393, 48264.78, 50697, 9.02, 1],\n",
    "        \"MLSM\": [45321, 45751.25, 4613, 2218, 200],\n",
    "        \"ILS\": [43493, 43783.05, 44312, 2218, 1114.8],\n",
    "        \"LNS with LS\": [43568, 44290.55, 45011, 2218, 3058.25],\n",
    "        \"LNS without LS\": [43595, 44507.05, 45558, 2218, 6717.85],\n",
    "        \"Greedy weighted cycle\": [45453.0, 46252.105, 47884.0, 0.4, 1],\n",
    "    },\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"Dataset B\", \"min\"),\n",
    "            (\"Dataset B\", \"mean\"),\n",
    "            (\"Dataset B\", \"max\"),\n",
    "            (\"Dataset B\", \"seconds/instance\"),\n",
    "            (\"Dataset B\", \"iterations\"),\n",
    "        ]\n",
    "    ),\n",
    ").T\n",
    "\n",
    "a_res.join(b_res).sort_values(by=(\"Dataset A\", \"mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't manage to achieve better results with LNS than we achieved with ILS. However, our results of LNS with and without LS are almost similar, meaning that 2 times more destroy and repair operations have +- same effect as polishing with local seacrh.\n",
    "Nevertheless, LNS, despite having the same time budget as MLSM resulted in smaller costs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
